# Solving the Async Stack Trace Problem

One of the top pain points in the [Rust 2025 Survey](https://blog.rust-lang.org/2025/02/rust-survey-2025.html) was **poor async stack traces**. async-inspect directly addresses this problem.

## The Problem

When an async function panics, traditional stack traces are nearly useless:

```
thread 'tokio-runtime-worker' panicked at 'database connection failed'
stack backtrace:
   0: std::panicking::begin_panic
   1: <core::pin::Pin<P> as core::future::future::Future>::poll
   2: tokio::runtime::task::core::Core<T,S>::poll
   3: tokio::runtime::task::harness::Harness<T,S>::poll
             at ~/.cargo/registry/src/tokio-1.0/src/runtime/task/harness.rs:150
   4: tokio::runtime::blocking::pool::Inner::run
   5: std::sys_common::backtrace::__rust_begin_short_backtrace
```

### What's Wrong?

‚ùå **No task context**: Which async task failed?
‚ùå **No async call chain**: What function called what?
‚ùå **No await point**: Where was the task blocked?
‚ùå **No state information**: What was the task doing?
‚ùå **Runtime internals only**: Just tokio/async-std internals

### Why Does This Happen?

Async functions are compiled into **state machines**:

```rust
// You write:
async fn fetch_user(id: u64) -> User {
    let profile = db.get_profile(id).await;
    let posts = db.get_posts(id).await;
    User { profile, posts }
}

// Compiler generates:
enum FetchUserState {
    Start { id: u64 },
    WaitProfile { id: u64, future: ProfileFuture },
    WaitPosts { profile: Profile, future: PostsFuture },
    Done,
}
```

When it panics, you only see the **poll machinery**, not your actual async code.

## The Solution: async-inspect

async-inspect captures **async-specific context** that normal stack traces can't provide.

### 1. Full Async Call Chain

**Traditional stack trace**:
```
tokio::runtime::task::harness::Harness<T,S>::poll
  at src/runtime/task/harness.rs:150
```

**async-inspect**:
```bash
$ async-inspect analyze --show-failures

Task #42: handle_request [PANICKED]
  ‚îú‚îÄ Location: src/api/handlers.rs:23
  ‚îú‚îÄ Duration: 5.2s before panic
  ‚îÇ
  ‚îî‚îÄ Async Call Chain:
     1. main::spawn_handler         (src/main.rs:45)
     2. handle_request(req)          (src/api/handlers.rs:23)
     3. ‚îú‚îÄ authenticate_user(token)  (src/auth.rs:67)  [50ms] ‚úÖ
     4. ‚îú‚îÄ fetch_user_data(id: 123) (src/users.rs:34)
     5. ‚îÇ  ‚îî‚îÄ db_query(sql)          (src/db.rs:89)    [5.1s] ‚ùå PANICKED
     6. ‚îî‚îÄ ‚ùå PANIC: "connection timeout"
```

### 2. Current Await Point

See **exactly where** the task was stuck:

```bash
Task #42 State:
  Status: PANICKED
  Blocked At: db_query().await
  Source: src/db.rs:89

  Code Context:
    87:     .bind(user_id)
    88:     .fetch_one(&pool)
    89: >>> .await?;  ‚Üê STUCK HERE FOR 5.2s
    90:
    91:     Ok(user)
```

### 3. Task Timeline

Understand what led to the panic:

```bash
$ async-inspect timeline --task 42

Task #42 Timeline:
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
  0ms   ‚îÇ ‚óè Task spawned
        ‚îÇ   handle_request(req: Request)
        ‚îÇ
  5ms   ‚îÇ ‚óè Entered: authenticate_user
 10ms   ‚îÇ ‚óã Poll::Pending (awaiting auth)
 45ms   ‚îÇ ‚óè Poll::Ready(token)
 50ms   ‚îÇ ‚úì authenticate_user completed
        ‚îÇ
 55ms   ‚îÇ ‚óè Entered: fetch_user_data
 60ms   ‚îÇ   ‚îî‚îÄ db_query started
 65ms   ‚îÇ     ‚óã Poll::Pending (awaiting connection)
100ms   ‚îÇ     ‚óã Poll::Pending (waiting...)
200ms   ‚îÇ     ‚óã Poll::Pending (waiting...)
500ms   ‚îÇ     ‚óã Poll::Pending (still waiting...)
        ‚îÇ     ... [polled 847 times]
5200ms  ‚îÇ ‚ùå TIMEOUT ‚Üí PANIC
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

‚ö†Ô∏è  Warning: Task polled 847 times without progress
    Possible cause: busy-wait loop or resource starvation
```

### 4. Related Tasks Analysis

Find patterns across failures:

```bash
$ async-inspect analyze --correlate

üîç Failure Analysis

Found 10 related failures (last 5 minutes):

Pattern: Database connection timeout
  Tasks: #38, #39, #40, #41, #42, #43, #44, #45, #46, #47
  All blocked at: db_query().await
  Common cause: Connection pool exhausted

Connection Pool Status:
  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
  ‚îÇ Active:    10/10  [FULL] ‚îÇ ‚ö†Ô∏è
  ‚îÇ Idle:       0/10         ‚îÇ
  ‚îÇ Waiting:   37 tasks      ‚îÇ ‚Üê Tasks waiting for connections
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Diagnosis: Connection pool saturation
  - All 10 connections in use
  - 37 tasks waiting for available connection
  - Average wait time: 5.2s ‚Üí timeout

Recommendations:
  1. Increase max_connections in database config
  2. Add connection timeout (currently unlimited)
  3. Implement connection retry with backoff
  4. Review slow queries holding connections
```

## Real-World Example

### Scenario: Production API Panic

Your production API starts panicking with this error:

```
thread 'tokio-runtime-worker' panicked at 'database error: connection timeout'
note: run with `RUST_BACKTRACE=1` for a backtrace
```

### Traditional Debugging Process

1. ‚ùå Stack trace shows only runtime internals
2. ‚ùå Add logging to every function manually
3. ‚ùå Reproduce locally (can't replicate production load)
4. ‚ùå Deploy, wait for it to happen again
5. ‚ùå Check logs, still not enough context
6. üò´ Hours/days of debugging

### With async-inspect

1. ‚úÖ Check dashboard immediately:

```bash
$ async-inspect monitor

Active Tasks: 47
Failed Tasks (last 5m): 12
Deadlocks: 0
‚ö†Ô∏è  High failure rate detected!

Failed Tasks:
  Task #42: handle_request [PANICKED] 5.2s
  Task #43: handle_request [PANICKED] 5.3s
  Task #44: handle_request [PANICKED] 5.1s
  ... [9 more]

Press 'd' for detailed analysis
```

2. ‚úÖ See the pattern:

```bash
$ async-inspect analyze --failures

Common Failure Pattern:
  Location: src/db.rs:89 (db_query().await)
  Cause: Connection timeout after 5s
  Affected: 12 tasks

Root Cause Analysis:
  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
  ‚îÇ Database connection pool exhausted  ‚îÇ
  ‚îÇ 10/10 connections active            ‚îÇ
  ‚îÇ 35+ tasks waiting                   ‚îÇ
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

3. ‚úÖ Fix immediately:

```rust
// Before (no timeout, no limit)
let pool = PgPoolOptions::new()
    .max_connections(10)
    .connect(db_url).await?;

// After (with timeout and more connections)
let pool = PgPoolOptions::new()
    .max_connections(50)           // ‚Üê Increase pool
    .acquire_timeout(Duration::from_secs(2))  // ‚Üê Add timeout
    .connect(db_url).await?;
```

4. ‚úÖ Verify fix:

```bash
$ async-inspect monitor

Active Tasks: 52
Failed Tasks (last 5m): 0  ‚úì
Average response time: 45ms

Connection Pool:
  Active:   12/50
  Idle:     38/50  ‚úì Healthy
  Waiting:  0
```

**Total time: 5 minutes** instead of hours/days.

## How to Use async-inspect for Stack Traces

### Setup

1. **Add instrumentation**:

```rust
use async_inspect::Inspector;

#[tokio::main]
async fn main() {
    // Initialize inspector
    let inspector = Inspector::new(Default::default());

    // Your app code
    run_server().await;
}

#[async_inspect::trace]  // ‚Üê Add to async functions
async fn handle_request(req: Request) -> Response {
    let user = authenticate(req).await?;
    let data = fetch_data(user.id).await?;
    render(data)
}
```

2. **Run with monitoring**:

```bash
# Terminal 1: Run your app
cargo run

# Terminal 2: Monitor tasks
async-inspect monitor
```

### When Something Panics

**Immediate triage**:

```bash
# See what failed
async-inspect analyze --show-failures

# Get detailed trace
async-inspect trace --task <id>

# Export for investigation
async-inspect export --json panic_trace.json
```

### Development Workflow

```bash
# During development
cargo run  # Inspector automatically enabled in debug mode

# In another terminal
async-inspect tui  # Live dashboard
```

### Production Deployment

```rust
// Low-overhead production config
let inspector = Inspector::new(Config {
    sampling_rate: 0.01,  // Only track 1% for low overhead
    capture_backtraces: false,
    mode: Mode::Production,
    ..Default::default()
});

// Export failures automatically
tokio::spawn(async move {
    loop {
        tokio::time::sleep(Duration::from_secs(60)).await;

        let failures = inspector.failed_tasks();
        if !failures.is_empty() {
            // Export to logging/monitoring system
            log::error!("Task failures: {:#?}", failures);
        }
    }
});
```

## Comparison with Other Solutions

### vs. RUST_BACKTRACE=1

| Feature | RUST_BACKTRACE | async-inspect |
|---------|----------------|---------------|
| Shows async call chain | ‚ùå No | ‚úÖ Yes |
| Shows await points | ‚ùå No | ‚úÖ Yes |
| Shows task state | ‚ùå No | ‚úÖ Yes |
| Shows task relationships | ‚ùå No | ‚úÖ Yes |
| Time in each state | ‚ùå No | ‚úÖ Yes |
| Works in production | ‚úÖ Yes | ‚úÖ Yes (low overhead) |
| Zero cost when disabled | ‚úÖ Yes | üü° Small |

### vs. tokio-console

| Feature | tokio-console | async-inspect |
|---------|---------------|---------------|
| Live task monitoring | ‚úÖ Yes | ‚úÖ Yes |
| Historical analysis | ‚ùå No | ‚úÖ Yes |
| Panic analysis | ‚ùå Limited | ‚úÖ Full |
| Deadlock detection | ‚úÖ Yes | ‚úÖ Yes |
| Export traces | ‚ùå No | ‚úÖ JSON/CSV |
| Production safe | üü° High overhead | ‚úÖ Low overhead |

**Best approach**: Use both!
- tokio-console for runtime observability
- async-inspect for debugging and failure analysis

### vs. tracing + tracing-subscriber

| Feature | tracing | async-inspect |
|---------|---------|---------------|
| Manual instrumentation | ‚úÖ Flexible | ‚úÖ Automatic |
| Task relationships | ‚ùå Limited | ‚úÖ Full graph |
| State machine visibility | ‚ùå No | ‚úÖ Yes |
| Await point tracking | ‚ùå No | ‚úÖ Yes |
| Integration | ‚úÖ Ecosystem | ‚úÖ Compatible |

async-inspect works **with** tracing via the `AsyncInspectLayer`!

## Future Improvements

The Rust project is working on better async diagnostics:

- [RFC: async stack traces](https://github.com/rust-lang/rfcs/pull/3457)
- Improved panic messages for async
- Better debugger integration

async-inspect will **complement** these improvements:

```rust
// Future: Better built-in stack traces
// + async-inspect: Full task context, relationships, timeline

// Best of both worlds!
```

## Common Scenarios

### Scenario 1: "My async function panics randomly"

```bash
# Run with async-inspect
async-inspect monitor --watch

# When it panics, you see:
Task #123: process_payment [PANICKED]
  Blocked at: external_api_call().await
  Poll count: 1 (panicked on first poll!)
  Error: "TLS handshake failed"

# Diagnosis: Network issue, not your code
```

### Scenario 2: "Tests fail intermittently"

```bash
# Run tests with tracing
RUST_LOG=async_inspect=debug cargo test

# Failing test shows:
Task #5: test_user_creation [FAILED]
  Deadlock detected!
  - Task #5 waiting on Task #6 (mutex)
  - Task #6 waiting on Task #5 (channel)

# Diagnosis: Classic deadlock
```

### Scenario 3: "Production slow requests"

```bash
async-inspect analyze --slow --threshold 1s

Slow Tasks (>1s):
  Task #42: handle_checkout [2.3s]
    ‚îú‚îÄ validate_cart      [50ms]  ‚úÖ
    ‚îú‚îÄ charge_payment     [2.1s]  ‚ö†Ô∏è  SLOW
    ‚îÇ  ‚îî‚îÄ external_api    [2.0s]  ‚Üê Problem!
    ‚îî‚îÄ send_confirmation  [100ms] ‚úÖ

# Diagnosis: External API slow, add timeout
```

## Best Practices

### 1. Annotate Critical Paths

```rust
// ‚úÖ GOOD: Annotate user-facing handlers
#[async_inspect::trace]
async fn api_handler() { }

// ‚úÖ GOOD: Annotate error-prone code
#[async_inspect::trace]
async fn risky_operation() { }

// ‚ùå BAD: Don't annotate everything
#[async_inspect::trace]
async fn tiny_helper() { }  // Too fine-grained
```

### 2. Use in Tests

```rust
#[tokio::test]
#[async_inspect::trace]  // ‚Üê Add this
async fn test_concurrent_access() {
    // If test fails, you get full async context
}
```

### 3. Production Sampling

```rust
Config {
    sampling_rate: 0.01,  // 1% overhead
    capture_backtraces: false,  // Expensive
    mode: Mode::Production,
}
```

### 4. Export Failures

```rust
// Auto-export failures for analysis
if let Some(failure) = inspector.last_failure() {
    let json = serde_json::to_string(&failure)?;
    log::error!("Task failure: {}", json);
}
```

## Limitations

async-inspect helps tremendously but **doesn't solve everything**:

- ‚ùå Doesn't replace proper error handling
- ‚ùå Doesn't fix bugs, just helps find them faster
- ‚ùå Small overhead even when optimized
- ‚ùå Requires instrumentation (manual or via tracing)

## Get Started

1. **Install**:
   ```bash
   cargo install async-inspect
   ```

2. **Add to project**:
   ```toml
   [dependencies]
   async-inspect = "0.1"
   ```

3. **Instrument**:
   ```rust
   #[async_inspect::trace]
   async fn your_function() { }
   ```

4. **Monitor**:
   ```bash
   async-inspect tui
   ```

That's it! Next time you hit an async panic, you'll have the context you need.

## Learn More

- [Installation Guide](./installation.md)
- [Quick Start](./quickstart.md)
- [Troubleshooting](./troubleshooting.md)
- [Examples](./examples.md)

---

**The async stack trace problem is real, but it's solvable.** async-inspect gives you the visibility you need to debug async Rust with confidence.
